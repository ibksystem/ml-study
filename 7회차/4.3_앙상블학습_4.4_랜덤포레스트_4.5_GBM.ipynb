{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:90% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:90% !important;}</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 앙상블 학습 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앙상블(Ensemble) 학습\n",
    "\n",
    "앙상블이란 여러 개의 알고리즘을 사용하여, 그 예측을 결함함으로써 보다 정확한 예측을 도출하는 기법을 말합니다.\n",
    "집단지성이 힘을 발휘하는 것처럼 단일의 강한 알고리즘보다 복수의 약한 알고리즘이 더 뛰어날 수 있다는 생각에 기반을 두고 있습니다. \n",
    "\n",
    "이미지, 영상, 음성 등의 비정형 데이터의 분류는 딥러닝이 뛰어난 성능을 보이지만, \n",
    "대부분 정형 데이터의 분류에서는 앙상블이 뛰어난 성능을 보이고 있다고 합니다. \n",
    "\n",
    "앙상블 학습의 유형은 보팅(Voting), 배깅(Bagging), 부스팅(Boosting), 스태킹(Stacking) 등이 있습니다. \n",
    "\n",
    "보팅은 여러 종류의 알고리즘을 사용한 각각의 결과에 대해 투표를 통해 최종 결과를 예측하는 방식입니다.\n",
    "배깅은 같은 알고리즘에 대해 데이터 샘플을 다르게 두고 학습을 수행해 보팅을 수행하는 방식입니다.\n",
    "이 때의 데이터 샘플은 중첩이 허용됩니다. 즉 10000개의 데이터에 대해 10개의 알고리즘이 배깅을 사용할 때,\n",
    "각 1000개의 데이터 내에는 중복된 데이터가 존재할 수 있습니다.\n",
    "배깅의 대표적인 방식이 Random Forest 입니다. \n",
    "\n",
    "부스팅은 여러 개의 알고리즘이 순차적으로 학습을 하되, 앞에 학습한 알고리즘 예측이 틀린 데이터에 대해\n",
    "올바르게 예측할 수 있도록, 그 다음번 알고리즘에 가중치를 부여하여 학습과 예측을 진행하는 방식입니다. \n",
    "\n",
    "마지막으로 스태킹은 여러 가지 다른 모델의 예측 결과값을 다시 학습 데이터로 만들어 다른 모델(메타 모델)로\n",
    "재학습시켜 결과를 예측하는 방법입니다.\n",
    "![보팅과배깅](vvb.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하드보팅(Hard Voting)과 소프트보팅(Soft Voting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하드보팅을 이용한 분류는 다수결 원칙과 비슷합니다.\n",
    "소프트 보팅은 각 알고리즘이 레이블 값 결정 확률을 예측해서, 이것을 평균하여 이들 중 확률이 가장 높은 레이블 값을 최종 값으로 예측합니다.\n",
    "\n",
    "일반적으로는 소프트 보팅이 성능이 더 좋아서 많이 적용됩니다.\n",
    "![](hvsv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 보팅분류기(Voting Classifier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런은 보팅방식의 앙상블을 구현한 VotingClassifier 클래스를 제공하고 있습니다.\n",
    "사이킷런에서 제공되는 위스콘신 유방암 데이터 세트를 이용해 보팅방식의 앙상블을 적용해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.5</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38           122.8     1001.0          0.11840   \n",
       "1        20.57         17.77           132.9     1326.0          0.08474   \n",
       "2        19.69         21.25           130.0     1203.0          0.10960   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33            184.6   \n",
       "1                 0.05667  ...         24.99          23.41            158.8   \n",
       "2                 0.05999  ...         23.57          25.53            152.5   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "data_df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "data_df.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로지스틱 회귀와 KNN을이용한 소프틉보팅 분류기 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting 분류기 정확도: 0.9474\n",
      "LogisticRegression 정확도: 0.9386\n",
      "KNeighborsClassifier 정확도: 0.9386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/envs/myenv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# 개별 모델은 로지스틱 회귀와 KNN 임. \n",
    "lr_clf = LogisticRegression()\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=8)\n",
    "\n",
    "# 개별 모델을 소프트 보팅 기반의 앙상블 모델로 구현한 분류기 \n",
    "vo_clf = VotingClassifier( estimators=[('LR',lr_clf),('KNN',knn_clf)] , voting='soft' )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, \n",
    "                                                    test_size=0.2 , random_state= 156)\n",
    "\n",
    "# VotingClassifier 학습/예측/평가. \n",
    "vo_clf.fit(X_train , y_train)\n",
    "pred = vo_clf.predict(X_test)\n",
    "print('Voting 분류기 정확도: {0:.4f}'.format(accuracy_score(y_test , pred)))\n",
    "\n",
    "# 개별 모델의 학습/예측/평가.\n",
    "classifiers = [lr_clf, knn_clf]\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train , y_train)\n",
    "    pred = classifier.predict(X_test)\n",
    "    class_name= classifier.__class__.__name__\n",
    "    print('{0} 정확도: {1:.4f}'.format(class_name, accuracy_score(y_test , pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 배깅(Bagging)이란?\n",
    "\n",
    " 배깅(Bagging)은 Bootstrap Aggregating의 약자로, 보팅(Voting)과는 달리 동일한 알고리즘으로 여러 분류기를 만들어 보팅으로 최종 결정하는 알고리즘 \n",
    "\n",
    "#### 배깅은 다음과 같은 방식으로 진행이 됩니다.\n",
    "\n",
    "* 동일한 알고리즘을 사용하는 일정 수의 분류기 생성 \n",
    "\n",
    "* 각각의 분류기는 부트스트래핑(Bootstrapping)방식으로 생성된 샘플데이터를 학습\n",
    "\n",
    "* 최종적으로 모든 분류기가 보팅을 통헤 예측 결정\n",
    "\n",
    "※ 부트스트래핑 샘플링은 전체 데이터에서 일부 데이터의 중첩을 허용하는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](bts.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 랜덤포레스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "랜덤 포레스트는 여러 개의 결정트리(Decision Tree)를 활용한 배깅 방식의 대표적인 알고리즘\n",
    "![](randomforesttraining.png)\n",
    "\n",
    "### 장점\n",
    "* 결정 트리의 쉽고 직관적인 장점을 그대로 가지고 있음\n",
    "* 앙상블 알고리즘 중 비교적 빠른 수행 속도를 가지고 있음\n",
    "* 다양한 분야에서 좋은 성능을 나타냄\n",
    "\n",
    "### 단점\n",
    "* 하이퍼 파라미터가 많아 튜닝을 위힌 시간이 많이 소요됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용자 행동 데이터 세트를 이용한 randomforest 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_feature_name_df(old_feature_name_df):\n",
    "    feature_dup_df = pd.DataFrame(data=old_feature_name_df.groupby('column_name').cumcount(),\n",
    "                                  columns=['dup_cnt'])\n",
    "    feature_dup_df = feature_dup_df.reset_index()\n",
    "    new_feature_name_df = pd.merge(old_feature_name_df.reset_index(), feature_dup_df, how='outer')\n",
    "    new_feature_name_df['column_name'] = new_feature_name_df[['column_name', 'dup_cnt']].apply(lambda x : x[0]+'_'+str(x[1]) \n",
    "                                                                                         if x[1] >0 else x[0] ,  axis=1)\n",
    "    new_feature_name_df = new_feature_name_df.drop(['index'], axis=1)\n",
    "    return new_feature_name_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_human_dataset( ):\n",
    "    \n",
    "    # 각 데이터 파일들은 공백으로 분리되어 있으므로 read_csv에서 공백 문자를 sep으로 할당.\n",
    "    feature_name_df = pd.read_csv('./human_activity/features.txt',sep='\\s+',\n",
    "                        header=None,names=['column_index','column_name'])\n",
    "    \n",
    "    # 중복된 피처명을 수정하는 get_new_feature_name_df()를 이용, 신규 피처명 DataFrame생성. \n",
    "    new_feature_name_df = get_new_feature_name_df(feature_name_df)\n",
    "    \n",
    "    # DataFrame에 피처명을 컬럼으로 부여하기 위해 리스트 객체로 다시 변환\n",
    "    feature_name = new_feature_name_df.iloc[:, 1].values.tolist()\n",
    "    \n",
    "    # 학습 피처 데이터 셋과 테스트 피처 데이터을 DataFrame으로 로딩. 컬럼명은 feature_name 적용\n",
    "    X_train = pd.read_csv('./human_activity/train/X_train.txt',sep='\\s+', names=feature_name )\n",
    "    X_test = pd.read_csv('./human_activity/test/X_test.txt',sep='\\s+', names=feature_name)\n",
    "    \n",
    "    # 학습 레이블과 테스트 레이블 데이터을 DataFrame으로 로딩하고 컬럼명은 action으로 부여\n",
    "    y_train = pd.read_csv('./human_activity/train/y_train.txt',sep='\\s+',header=None,names=['action'])\n",
    "    y_test = pd.read_csv('./human_activity/test/y_test.txt',sep='\\s+',header=None,names=['action'])\n",
    "    \n",
    "    # 로드된 학습/테스트용 DataFrame을 모두 반환 \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤 포레스트 정확도: 0.9253\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 결정 트리에서 사용한 get_human_dataset( )을 이용해 학습/테스트용 DataFrame 반환\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()\n",
    "\n",
    "# 랜덤 포레스트 학습 및 별도의 테스트 셋으로 예측 성능 평가\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "rf_clf.fit(X_train , y_train)\n",
    "pred = rf_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test , pred)\n",
    "print('랜덤 포레스트 정확도: {0:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 랜덤포레스트 하이퍼 파라미터 및 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|_파라미터 명_|_설명_|\n",
    "|---|---|\n",
    "|n_estimators|\t- 결정트리의 갯수를 지정<br>- Default = 10<br>- 무작정 트리 갯수를 늘리면 성능 좋아지는 것 대비 시간이 걸릴 수 있음|\n",
    "|min_samples_split|\t- 노드를 분할하기 위한 최소한의 샘플 데이터수 \n",
    "→ 과적합을 제어하는데 사용<br>- Default = 2 → 작게 설정할 수록 분할 노드가 많아져 과적합 가능성 증가|\n",
    "|min_samples_leaf|\t- 리프노드가 되기 위해 필요한 최소한의 샘플 데이터수<br>- min_samples_split과 함께 과적합 제어 용도<br>- 불균형 데이터의 경우 특정 클래스의 데이터가 극도로 작을 수 있으므로 작게 설정 필요|\n",
    "|max_features|\t- 최적의 분할을 위해 고려할 최대 feature 개수<br>- Default = 'auto' (결정트리에서는 default가 none이었음)<br>- int형으로 지정 →피처 갯수 / float형으로 지정 →비중<br>- sqrt 또는 auto : 전체 피처 중 √(피처개수) 만큼 선정<br>- log : 전체 피처 중 log2(전체 피처 개수) 만큼 선정|\n",
    "|max_depth|\t- 트리의 최대 깊이<br>- default = None<br>→ 완벽하게 클래스 값이 결정될 때 까지 분할 또는 데이터 개수가 min_samples_split보다 작아질 때까지 분할<br>- 깊이가 깊어지면 과적합될 수 있으므로 적절히 제어 필요\n",
    "|max_leaf_nodes|\t리프노드의 최대 개수|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GridSearchCV를 통한 랜덤포레스트 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[100],\n",
    "    'max_depth' : [6, 8, 10, 12], \n",
    "    'min_samples_leaf' : [8, 12, 18 ],\n",
    "    'min_samples_split' : [8, 16, 20]\n",
    "}\n",
    "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "rf_clf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "grid_cv = GridSearchCV(rf_clf , param_grid=params , cv=2, n_jobs=-1 )  # (n_jobs=-1)모든 CPU 코어를 이용해 학습진행 가능\n",
    "grid_cv.fit(X_train , y_train)\n",
    "\n",
    "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf1 = RandomForestClassifier(n_estimators=300, max_depth=10, min_samples_leaf=8, \\\n",
    "                                 min_samples_split=8, random_state=0)\n",
    "rf_clf1.fit(X_train , y_train)\n",
    "pred = rf_clf1.predict(X_test)\n",
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test , pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "ftr_importances_values = rf_clf1.feature_importances_\n",
    "ftr_importances = pd.Series(ftr_importances_values,index=X_train.columns  )\n",
    "ftr_top20 = ftr_importances.sort_values(ascending=False)[:20]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Feature importances Top 20')\n",
    "sns.barplot(x=ftr_top20 , y = ftr_top20.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4.5 GBM(Gradient Boosting Machine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "부스팅 알고리즘은 여러 개의 약한 학습기(weak learner)를 순차적으로 학습-예측하면서 잘못 예측한 데이터에 가중치를 부여해 오류를 개선해나가며 학습하는 방식\n",
    "\n",
    "AdaBoost (adaptiveboosting)\n",
    "\n",
    "![](ada.png)\n",
    "\n",
    "Step 1) 첫 번째 약한 학습기가 첫번째 분류기준(D1)으로 + 와 - 를 분류\n",
    "\n",
    "Step 2) 잘못 분류된 데이터에 대해 가중치를 부여(두 번쨰 그림에서 커진 + 표시)\n",
    "\n",
    "Step 3) 두 번째 약한 학습기가 두번째 분류기준(D2)으로 +와 - 를 다시 분류\n",
    "\n",
    "Step 4) 잘못 분류된 데이터에 대해 가중치를 부여(세 번째 그림에서 커진 - 표시)\n",
    "\n",
    "Step 5) 세 번째 약한 학습기가 세번째 분류기준으로(D3) +와 -를 다시 분류해서 오류 데이터를 찾음\n",
    "\n",
    "Step 6) 마지막으로 분류기들을 결합하여 최종 예측 수행\n",
    "\n",
    "→ 약한 학습기를 순차적으로 학습시켜, 개별 학습기에 가중치를 부여하여 모두 결합함으로써 개별 약한 학습기보다 높은 정확도의 예측 결과를 만듦\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boost Machine(GBM)¶\n",
    "\n",
    "AdaBoost와 유사하지만, 가중치 업데이트를 경사하강법(Gradient Descent)를 이용하여 최적화된 결과를 얻는 알고리즘입니다.\n",
    "\n",
    "GBM은 예측 성능이 높지만 Greedy Algorithm으로 과적합이 빠르게되고, 시간이 오래 걸린다는 단점이 있습니다.\n",
    "\n",
    "※ 경사하강법\n",
    "\n",
    "분류의 실제값을 y, 피처에 기반한 예측함수를 F(x), 오류식을 h(x) = y-F(x)라고 하면 이 오류식을 최소화하는 방향성을 가지고 가중치 값을 업데이트\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM 정확도: 0.9386\n",
      "GBM 수행 시간: 448.4 초 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()\n",
    "\n",
    "# GBM 수행 시간 측정을 위함. 시작 시간 설정.\n",
    "start_time = time.time()\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=0)\n",
    "gb_clf.fit(X_train , y_train)\n",
    "gb_pred = gb_clf.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "\n",
    "print('GBM 정확도: {0:.4f}'.format(gb_accuracy))\n",
    "print(\"GBM 수행 시간: {0:.1f} 초 \".format(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GBM 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "|파라미터 명\t|설명|\n",
    "|---|---|\n",
    "|loss|\t- 경사하강법에서 사용할 cost function 지정<br>- 특별한 이유가 없으면 default 값인 deviance 적용|\n",
    "|n_estimators|\t- 생성할 트리의 갯수를 지정<br>- Default = 100<br>- 많을소록 성능은 좋아지지만 시간이 오래 걸림|\n",
    "|learning_rate|\t- 학습을 진행할 때마다 적용하는 학습률(0~1)<br>- Weak learner가 순차적으로 오류 값을 보정해나갈 때 적용하는 계수<br>- Default = 0.1<br>- 낮은 만큼 최소 오류 값을 찾아 예측성능이 높아질 수 있음<br>- 하지만 많은 수의 트리가 필요하고 시간이 많이 소요|\n",
    "|subsample|\t- 개별 트리가 학습에 사용하는 데이터 샘플링 비율(0~1)<br>- default=1 (전체 데이터 학습)<br>- 이 값을 조절하여 트리 간의 상관도를 줄일 수 있음|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV를 통한 GBM의 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 15.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼 파라미터:\n",
      " {'learning_rate': 0.05, 'n_estimators': 500}\n",
      "최고 예측 정확도: 0.9010\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[100, 500],\n",
    "    'learning_rate' : [ 0.05, 0.1]\n",
    "}\n",
    "grid_cv = GridSearchCV(gb_clf , param_grid=params , cv=2 ,verbose=1)\n",
    "grid_cv.fit(X_train , y_train)\n",
    "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM 정확도: 0.9410\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV를 이용하여 최적으로 학습된 estimator로 predict 수행. \n",
    "gb_pred = grid_cv.best_estimator_.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "print('GBM 정확도: {0:.4f}'.format(gb_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
